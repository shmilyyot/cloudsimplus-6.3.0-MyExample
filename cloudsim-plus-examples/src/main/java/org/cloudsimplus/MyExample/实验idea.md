# 实验过程

### 目标：一个模拟数据中心，给定一组输入的真实任务流（tasks），模拟系统真实调度过程，从CPU、内存等多维度资源预测出发，实现新的迁移后放置算法。

### 指标：

1. 减少系统消耗的总能耗
2. 减少主机（host）的开机数目
3. 减少虚拟机（vm）迁移次数
4. 减少SLA违反次数

### 实验设置：

##### 		使用CloudSim Plus模拟器搭建模拟数据中心。

##### 		目前已实现BaseLine的对比算法，即使用Static静态的过载以及欠载阈值，使用最佳适应算法放置的迁移算法。

##### 		打算在接下来的工作中先实现基于预测的虚拟机迁移后放置算法。

## 迁移后放置算法过程：

##### 		当虚拟机超出或低于阈值，先预测（还没决定用什么预测算法）是否会在未来K个阶段也超出阈值或低于阈值，只要有一个未来利用率不符合要求，即进行迁移



不能使用静态阈值迁移，真实的数据集虚拟机利用率很低，根据静态阈值会导致大量主机尝试迁移。也许可以根据PABFD，资源均衡程度选择最好的一个欠载服务器迁移。

要不直接取消低阈值迁移，每次只尝试把功耗最低的迁移

目前的策略，设置阈值，可能造成大量虚拟机需要迁移。

不设置阈值，每次固定迁移最低的一个，有可能造成系统状态平稳还进行迁移。

打标记，如果一个低负载主机频繁发生迁移失败数次以上（3次？），考虑整合服务器，

1. 提高它的阈值，让它成为可以被迁入的服务器
2. 并且跳过它，不迁移它，选下一个最低的进行迁移

若低负载主机有多个vm，则形成一个cluster，按cludter排序

##### 		选择一个虚拟机选择迁出（哪一个维度超出，就重点照顾哪个维度。选择那个维度虚拟机利用率最高的而迁出），然后用预测算法推测出虚拟机每一个维度在未来K个时段的利用率，选择每一个维度中最大的利用率作为约束（防止未来的虚拟机利用率增长导致主机过载又迁出），形成一个新的虚拟机vm'规格要求。

##### 		然后开始选择host来进行放置，采用同样的预测算法，预测出每一个host每一个维度资源的K个时段的最小的剩余利用率（确保主机资源在未来也放得下该虚拟机，防止后续又因为资源不足导致迁移）作为host'的新的约束条件。

##### 		将vm‘的资源利用率与每一个host’的剩余资源利用率进行拟合，采用类似余弦相似度或者欧氏距离等公式，计算出资源最吻合最互补的host‘作为放置虚拟机的目的地。

1. PA-Vector-MUP：先对虚拟机降序排序，按cpu利用率，相当于pa，先把能耗高的迁移走。对host进行相似度排序，（相似度相同，按pa排序）从高到低，然后采用pa选择host，加上预测
2. 服务器绝大部分利用率都很低。防止频繁触发低阈值迁移，将正常服务器的pa从低到高排序，优先选择功耗最低的服务器，然后和vm‘进行相似度计算，放置所有相似度高的虚拟机进去。以此类推
3. 以下是我提出的power-awere-similiarty-Mitimuple-prediction（PA-S-MUP）
4. 先预测每一个维度资源的利用率，同样的出vm和host的约束。将host按照功耗从高到低排序，选出第一个host，将vm按照和host的相似度排序，相似度在0~1之间，可以看作系数，再计算出每个vm的请求mips数目（和power间接相关），mips*相似度最大值可以看作整合放进host之后整合程度最高。循环直到所有vm迁移完成或者host放不下任何vm
5. 先预测每一个维度资源的利用率，同样的出vm和host的约束。将所有虚拟机按照请求的mips数目（利用率*核心数）从大到小排序，选择第一个vm，和每一个host计算相似度看作系数，选择能放下的host，（vm的mips+服务器请求的mips/host总共的mips）乘以功耗乘以相似度的最大值看作最佳整合

##### 如果没有host可以放下虚拟机，尝试整合静滞主机。尝试把正常运行的主机进一步整合腾出更多空间。尽量整合主机资源利用率比较高的主机，把其中资源释放后+原本剩余资源大于待迁移虚拟机的放下来。然后整合以迁移开销换服务器开销。

### 数据流来源：

##### 		已有论文主要采用PlanetLab和Google的数据，亦或是自己生成的随机数据。它们提供了数百万的tasks在持续一个月内的资源利用率变化，给的是一个请求资源的比例而不是具体的请求资源的数目，每一个task都可以映射成一个虚拟机vm

##### 		因为PlanetLab的数据只有CPU利用率，所以打算采用Google的数据。

##### 		目前已经对Google进行初略分析，在对利用率低于0.5%的情况进行过滤之后，发现剩余的task的平均利用率依然非常低，不管是cpu还是内存利用率都是12%左右，能够达到利用率在50%以上的数据估计不到总数据量的1%，而且是时间离散的。即导致生成的大量虚拟机利用率非常低，从该数据集的特征来看，在系统中放置这些虚拟机，几乎不可能使host达到过载迁移的情况。这与目前看到过的使用Google数据集的论文结论有冲突。

##### 		接下来的工作还需要继续对Google的数据进行进一步处理分析。



#### 此外，此前曾提到伪饱和的情况，还可以继续考虑

